import cv2
import dlib
import os
import time
import numpy as np
from Dlib import get_face_descriptor
from PIL import ImageFont, ImageDraw, Image

# „É¢„Éá„É´„Éï„Ç°„Ç§„É´„Çí„É≠„Éº„Éâ
predictor_path = "shape_predictor_68_face_landmarks.dat"
# ÂøÖË¶Å„Å™„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åô„Çã„ÅãÁ¢∫Ë™ç
if not os.path.exists(predictor_path):
    print("„Ç®„É©„Éº: „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    print(f"- {predictor_path}")
    exit()

# ‰øùÂ≠òÂÖà„ÅÆ„É´„Éº„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™
SAVE_ROOT_DIR = "face_data"
# È°îÊ§úÂá∫Âô®„Å®„É©„É≥„Éâ„Éû„Éº„ÇØ‰∫àÊ∏¨Âô®„Çí„É≠„Éº„Éâ
detector = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor(predictor_path)

# Êó•Êú¨Ë™û„Éï„Ç©„É≥„Éà„Çí„É≠„Éº„Éâ
font_path = r"C:\Windows\Fonts\meiryo.ttc"
if not os.path.exists(font_path):
    print("Ë≠¶Âëä: Êó•Êú¨Ë™û„Éï„Ç©„É≥„Éà„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    print(f"„Éï„Ç©„É≥„Éà„Éë„Çπ: {font_path} „ÇíÁí∞Â¢É„Å´Âêà„Çè„Åõ„Å¶‰øÆÊ≠£„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    exit()

font = ImageFont.truetype(font_path, 20)

# OpenCV„ÅÆÁîªÂÉè„Å´Êó•Êú¨Ë™û„ÉÜ„Ç≠„Çπ„Éà„ÇíÊèèÁîª„Åô„ÇãÈñ¢Êï∞
def draw_japanese_text(img, text, position, font, color):
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=(color[2], color[1], color[0]))
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def save_detected_face_with_name():
    """
    ÂêçÂâç„ÇíÂÖ•Âäõ„Åó„Å¶È°îÁîªÂÉè„Çí‰øùÂ≠ò„Åô„ÇãÈñ¢Êï∞
    """
    person_name = input("‰øùÂ≠ò„Åô„Çã‰∫∫Áâ©„ÅÆÂêçÂâç„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ: ").strip()
    if not person_name:
        print("„Ç®„É©„Éº: ÂêçÂâç„ÅåÂÖ•Âäõ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ")
        return

    save_dir = os.path.join(SAVE_ROOT_DIR, person_name)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        print(f"„Éá„Ç£„É¨„ÇØ„Éà„É™ '{save_dir}' „Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü„ÄÇ")

    capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    if not capture.isOpened():
        capture = cv2.VideoCapture(1, cv2.CAP_DSHOW)
    
    if not capture.isOpened():
        print("„Ç®„É©„Éº: „Ç´„É°„É©„Å´Êé•Á∂ö„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
        return

    print("„Ç´„É°„É©„ÇíËµ∑Âãï„Åó„Åæ„Åó„Åü„ÄÇÈ´òÂìÅË≥™„Å™È°î„ÅåÊ§úÂá∫„Åï„Çå„Çã„Å®„ÄÅÁîªÂÉè„Åå‰øùÂ≠ò„Åï„Çå„Åæ„Åô„ÄÇ")
    print(f"„Äé{person_name}„Äè„Åï„Çì„ÅÆÈ°î„ÇíÊò†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'Esc' „Ç≠„Éº„ÇíÊäº„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

    # üí° Â§âÊõ¥ÁÇπ1: „Ç¶„Ç£„É≥„Éâ„Ç¶„Çí‰∫ãÂâç„Å´‰ΩúÊàê„Åó„ÄÅÂêçÂâç„Çí‰ªò„Åë„Çã üí°
    window_name = "face saver"
    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)

    # üí° Â§âÊõ¥ÁÇπ2: „Ç¶„Ç£„É≥„Éâ„Ç¶„ÇíÂ∏∏„Å´ÊúÄÂâçÈù¢„Å´Ë®≠ÂÆö üí°
    cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)

    image_count = 1
    face_detected_time = None
    frame_count = 0
    detection_frequency = 5
    dets = []
    
    live_status_text = "ÂæÖÊ©ü‰∏≠..."
    live_status_color = (255, 255, 255) # ÁôΩ

    while True:
        ret, frame = capture.read()
        if not ret:
            print("„Ç®„É©„Éº: „Éï„É¨„Éº„É†„ÅÆÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ")
            break

        frame = cv2.flip(frame, 1)
        
        if frame_count % detection_frequency == 0:
            dets = detector(frame, 1)
        frame_count += 1
        
        if len(dets) > 0:
            rect = dets[0]
            # „Åì„Åì„Å´È°î„ÅÆÊû†„ÇíÊèèÁîª„Åô„ÇãË°å„ÇíËøΩÂä†
            cv2.rectangle(frame, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)

            shape = sp(frame, rect)
            
            is_good_quality = True
            
            center_x = (rect.left() + rect.right()) / 2
            center_y = (rect.top() + rect.bottom()) / 2
            frame_center_x = frame.shape[1] / 2
            frame_center_y = frame.shape[0] / 2
            
            if abs(center_x - frame_center_x) > 100 or abs(center_y - frame_center_y) > 100:
                is_good_quality = False
                live_status_text = "È°î„Çí„ÇÇ„Å£„Å®‰∏≠Â§Æ„Å´!"
                live_status_color = (0, 165, 255) # „Ç™„É¨„É≥„Ç∏
            
            face_size = rect.area()
            min_size = 15000
            max_size = 80000
            if face_size < min_size:
                is_good_quality = False
                live_status_text = "È°î„Çí„ÇÇ„Å£„Å®Ëøë„Å•„Åë„Å¶!"
                live_status_color = (0, 0, 255) # Ëµ§
            elif face_size > max_size:
                is_good_quality = False
                live_status_text = "È°î„Çí„ÇÇ„Å£„Å®Èõ¢„Åó„Å¶!"
                live_status_color = (0, 0, 255) # Ëµ§
                
            left_eye = shape.part(36)
            right_eye = shape.part(45)
            eye_y_diff = abs(left_eye.y - right_eye.y)
            eye_x_diff = abs(left_eye.x - right_eye.x)
            
            if eye_x_diff > 0 and (eye_y_diff / eye_x_diff) > 0.3:
                is_good_quality = False
                live_status_text = "È°î„Çí„Åæ„Å£„Åô„Åê„Å´!"
                live_status_color = (0, 165, 255) # „Ç™„É¨„É≥„Ç∏
                
            if is_good_quality:
                live_status_text = "OKÔºÅÁîªÂÉè„Çí‰øùÂ≠ò„Åó„Åæ„Åô"
                live_status_color = (0, 255, 0) # Á∑ë
                
                if face_detected_time is None:
                    face_detected_time = time.time()
                
                if time.time() - face_detected_time > 2.0:
                    expanded_rect = dlib.rectangle(
                        max(0, rect.left() - 50), 
                        max(0, rect.top() - 50), 
                        min(frame.shape[1], rect.right() + 50), 
                        min(frame.shape[0], rect.bottom() + 50)
                    )
                    
                    face_img = frame[expanded_rect.top():expanded_rect.bottom(), expanded_rect.left():expanded_rect.right()]
                    
                    if face_img is not None and face_img.size > 0:
                        file_path = os.path.join(save_dir, f"{image_count}.jpg")
                        success = cv2.imwrite(file_path, face_img)
                        if success:
                            test_descriptor, test_error_msg = get_face_descriptor(file_path)
                            if test_descriptor is not None:
                                print(f"ÁîªÂÉè„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {file_path}")
                                print("‚úÖ Ëá™Â∑±Ê§úË®º„Å´ÊàêÂäü„Åó„Åæ„Åó„ÅüÔºÅ„Åì„ÅÆÁîªÂÉè„ÅØË™çË®º„Å´‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ")
                                image_count += 1
                                face_detected_time = None
                                live_status_text = "Ëá™Â∑±Ê§úË®ºOKÔºÅ"
                                live_status_color = (0, 255, 0)
                            else:
                                os.remove(file_path)
                                print(f"‚ùå Ëá™Â∑±Ê§úË®º„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {test_error_msg} -> ÂÜçÊíÆÂΩ±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
                                face_detected_time = None
                                live_status_text = "Ëá™Â∑±Ê§úË®ºNG"
                                live_status_color = (0, 0, 255)
                        else:
                            print(f"„Ç®„É©„Éº: ÁîªÂÉè„ÅÆ‰øùÂ≠ò„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Éï„Ç°„Ç§„É´„Éë„Çπ: {file_path}")
                            face_detected_time = None
                    else:
                        print("Ë≠¶Âëä: Ê§úÂá∫„Åï„Çå„ÅüÈ°î„ÅÆÂàá„ÇäÊäú„Åç„ÅåÁ©∫„Åß„Åó„Åü„ÄÇ")
                        face_detected_time = None
            else:
                face_detected_time = None
        else:
            live_status_text = "È°î„ÇíÊ§úÂá∫„Åß„Åç„Åæ„Åõ„Çì"
            live_status_color = (255, 255, 255)
            face_detected_time = None

        frame = draw_japanese_text(frame, live_status_text, (50, 50), font, live_status_color)
        
        if len(dets) > 0:
            rect = dets[0]
            frame = draw_japanese_text(frame, "È°î„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü", (rect.left(), rect.top() - 25), font, (0, 255, 0))

        cv2.imshow(window_name, frame)
        
        if cv2.waitKey(1) == 27:
            break

    capture.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    save_detected_face_with_name()